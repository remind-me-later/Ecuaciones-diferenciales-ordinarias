\documentclass[../ecuaciones_diferenciales.tex]{subfiles}

\begin{document}

En este capítulo estudiaremos métodos para resolver sistemas de ecuaciones
diferenciales. Definimos primero el caso general, aunque en este curso nos
restrigiremos al caso lineal.

Sean \(x_1, x_2, \dots, x_n \in C^1(\alpha, \omega)\) variables, que son
funciones de clase \(C^1\) sobre un intervalo de \(\R\).

\begin{definition}
	Un \emph{sistema de ecuaciones diferenciales de primer orden} es un sistema de la
	forma
	\[\eqsys{
			x'_1 &= f_1(t, x_1, x_2, \dots, x_n) \\
			x'_2 &= f_2(t, x_1, x_2, \dots, x_n) \\
			&\vdots \\
			x'_n &= f_n(t, x_1, x_2, \dots, x_n)}\]
\end{definition}

\begin{definition}
	\label{def:siseq1ord}
	Un \emph{sistema de ecuaciones diferenciales lineales de primer orden} es de la
	forma
	\[\eqsys{
			x'_1 &= a_{11}(t)x_1 + a_{12}(t)x_2 + \dots + a_{1n}(t)x_n + b_1(t) \\
			x'_2 &= a_{21}(t)x_1 + a_{22}(t)x_2 + \dots + a_{2n}(t)x_n + b_2(t) \\
			&\vdots \\
			x'_n &= a_{n1}(t)x_1 + a_{n2}(t)x_2 + \dots + a_{nn}(t)x_n + b_n(t)}\]
	donde \(a_{ij}\), \(b_i\) son funciones continuas en un intervalo
	\((\alpha, \omega) \subset \R\) para \(i,j = 1, \dots, n\).
\end{definition}

\begin{notation}
	Denotaremos los vectores mediante una raya por encima: \(\vec{x} \in \R^n\).
\end{notation}

Podemos expresar un sistema de este tipo en forma matricial como
\[\vec{x}' = A\vec{x} + \vec{b}\]
donde \(\vec{x} : (\alpha, \omega) \subset \R \to \R^n\),
\(A \in \mathcal{M}_{n \times n}(\R)\) y
\(\vec{b} : (\alpha, \omega) \subset \R \to \R^n\) son tales que
\[\vec{x} = \vec{x}(t) = \mat{x_1(t) \\ x_2(t) \\ \vdots \\ x_n(t)}, \quad
	A = A(t) = \mat{a_{ij}(t)}^n_{i,j = 1},\quad
	\vec{b} = \vec{b}(t) = \mat{b_1(t) \\ b_2(t) \\ \vdots \\ b_n(t)} \]
y las derivadas e integrales se aplican \textquote{coordenada a coordenada},
i. e.
\[\vec{x}' = \mat{x'_1(t) \\ x'_2(t) \\ \vdots \\ x'_n(t)}
	= \mat{x'_1 \\ x'_2 \\ \vdots \\ x'_n}, \quad
	A' = \mat{a'_{ij}(t)}^n_{i,j = 1}, \quad
	\int A(s) \dif s = \mat{\int a_{ij} \dif s}^n_{i,j = 1}.\]

\section{Problema de valor inicial}

El problema de valor inicial para un sistema en forma matricial se define de
forma análoga a la forma escalar, cambiando escalares por vectores donde sea
necesario:

\begin{definition}
	Sean \(t_0 \in (\alpha, \omega)\) y
	\(\vec{x}^0 = \mat{x^0_1, x^0_2, \dots, x^0_n} \in \R^n\), entonces
	el \emph{problema de valor inicial} asociado a~\ref{def:siseq1ord} es de la forma
	\[\eqsys{
		\vec{x}' = A(t)\vec{x} + \vec{b}(t) \\
		\vec{x}(t_0) = \vec{x}^0}\]
\end{definition}

Probaremos que el problema de valor inicial tiene solución única en todo el
dominio \((\alpha, \omega)\), para ello representaremos el problema como una
ecuación integral, es una estrategia general en análisis intentar representar
las funciones como integrales debido a su buen comportamiento.

\begin{notation}
	Denotaremos por \(C(I, \R^n)\) el espacio vectorial de las funciones
	continuas del intervalo \(I \subset \R\) en \(\R^n\).
\end{notation}

Que \(\vec{x}\) sea solución del problema de valor inicial definido
anteriormente equivale a
\[\vec{x}(t) = \vec{x}^0 + \int_{t_0}^t A(s)\vec{x}(s) + \vec{b}(s) \dif s.\]

A raíz de esto, resulta natural definir el siguiente operador:
\begin{align*}
    T : C((\alpha, \omega), \R^n) & \to C((\alpha, \omega), \R^n) \\
    \phi                          & \mapsto
    \vec{x}^0 + \int_{t_0}^t A(s) \phi(s) + \vec{b}(s) \dif s.
\end{align*}

De esta forma, es evidente que \(\vec{x}\) es solución del sistema si y solo si
\(T(\vec{x}) = \vec{x}\), por lo que si demostramos que el operador \(T\) tiene
un único punto fijo habremos terminado.

\begin{remark}
	En realidad, \(T(\vec{\phi}) \in C^1((\alpha, \omega), \R^n)\) para
	\(\vec{\phi} \in C((\alpha, \omega), \R^n)\);
	hemos definido \(T\) con espacio de
	llegada \(C((\alpha, \omega), \R^n)\), del que
	\(C^1((\alpha, \omega), \R^n)\) es subespacio vectorial,
	para poder aplicar el teorema del punto fijo de
	Banach, que requiere espacios de salida y llegada iguales.
\end{remark}

Consideraremos \(\alpha < \tilde{\alpha} < t_0 < \tilde{\omega} < \omega\), y
demostraremos que \(T\) tiene un único punto fijo como operador en
\(C([\tilde{\alpha}, \tilde{\omega}], \R^n)\). Haciendo tender \(\tilde{\alpha}
\to \alpha,\ \tilde{\omega} \to \omega\), tendremos el resultado deseado.

Antes de seguir necesitamos recordar algunos resultados de cálculo diferencial,
aunque demostraremos solo los que introduzcan algún concepto nuevo con respecto
a lo visto en esa materia.

\begin{definition}[Espacio métrico completo]
	Un espacio métrico es \emph{completo} si toda sucesión de Cauchy es convergente.
\end{definition}

\begin{theorem}[Punto fijo de Banach]
	Sean \((X, d)\) un espacio métrico completo y \(T : X \to X\) una aplicación
	contractiva (es decir, Lipschitz con constante \(\alpha \in [0, 1)\)),
	entonces \(T\) tiene un único punto fijo.
\end{theorem}

Este teorema tiene una consecuencia que nos será muy útil.

\begin{corollary} \label{cor:banach_fixed_point}
	Sean \((X, d)\) un espacio métrico completo y \(T : X \to X\) tal que
	\(T^m = T \circ \overset{m}{\cdots} \circ T\) es contractiva para algún
	\(m \in \N\), entonces \(T\) tiene un único punto fijo.
\end{corollary}

Definimos ahora la distancia respecto a la cual el espacio
\(C([\tilde{\alpha}, \tilde{\omega}], \R^n)\) es completo.

\begin{definition}[Distancia entre funciones]
	Definimos en \(C([\tilde{\alpha}, \tilde{\omega}], \R^n)\) la distancia
	\[d(\vec{f}, \vec{g}) \eqdef \norm{\vec{f} - \vec{g}}_{\infty}
		= \max_{t \in [\tilde{\alpha}, \tilde{\omega}]}
			\norm{\vec{f}(t) - \vec{g}(t)}_2,\]
	donde \(\norm{\cdot}_2\) es la norma euclídea en \(\R^n\).
\end{definition}

\begin{proposition}
	\((C([\tilde{\alpha}, \tilde{\omega}], \R^n), d)\)
	es un espacio métrico completo.
\end{proposition}

\begin{proof}
	Para comprobar que \(d\) es una distancia, basta ver que
	\[\norm{\vec{f}}_\infty
		\eqdef \max_{t \in [\tilde{\alpha}, \tilde{\omega}]}
			\norm{\vec{f}(t)}_2\]
	es una norma (basta usar que \(\norm{\cdot}_2\) es una norma y las
	propiedades del máximo).

	Para ver que es completo, consideramos \((\vec{f}_n)_n\) una sucesión de
	Cauchy arbitraria en \(C([\tilde{\alpha}, \tilde{\omega}], \R^n)\),
	lo que quiere decir que para cualquier \(\epsilon > 0\) existe un
	natural \(N_0\) tal que si \(n, m \geq N_0\) entonces
	\[\norm{\vec{f}_n - \vec{f}_m}_\infty
		= d(\vec{f}_n, \vec{f}_m) < \epsilon.\]
	Fijamos ahora \(t_0 \in [\tilde{\alpha}, \tilde{\omega}]\) y consideramos la
	sucesión \((\vec{f}_n(t_0))_n \subset \R^n\), que es de Cauchy porque
	\[\norm{\vec{f}_n(t_0) - \vec{f}_m(t_0)}_2
		\leq \norm{\vec{f}_n - \vec{f}_m}_\infty.\]
	Usamos la completitud de \(\R^n\) para obtener un límite
	\(\vec{f}(t_0) = \lim_n \vec{f}_n(t_0)\), lo
	que nos proporciona una función
	\(\vec{f}: [\tilde{\alpha}, \tilde{\omega}] \to \R^n\) que será la candidata
	a límite. Lo único que nos queda por ver es que
	\(\vec{f} \in C([\tilde{\alpha}, \tilde{\omega}], \R^n)\) y
	\(\vec{f}_n \overset{d}{\to} \vec{f}\).

	Dado \(\epsilon > 0\), existe \(N_0 \in \N\) tal que si \(n, m \geq N_0\)
	entonces
	\[\norm{\vec{f}_n(t) - \vec{f}_m(t)}_2
		\leq \norm{\vec{f}_n - \vec{f}_m}_\infty < \epsilon\]
	para todo \(t \in [\tilde{\alpha}, \tilde{\omega}]\), y haciendo tender
	\(m \to \infty\), se tiene que
	\(\norm{\vec{f}_n(t) - \vec{f}(t)}_2 \leq \epsilon\) para todo
	\(t \in [\tilde{\alpha}, \tilde{\omega}]\), de donde
	\(\norm{\vec{f}_n - \vec{f}}_\infty \leq \epsilon\).

	Queda así demostrado que \(\vec{f}_n \to \vec{f}\) uniformemente;
	por un lado, esto implica que \(\vec{f}_n \overset{d}{\to} \vec{f}\) y,
	por otro, que \(\vec{f}\) es continua (por serlo las \(\vec{f}_n\)).
\end{proof}

\begin{remark}
	La estrategia de esta demostración para probar la completitud es frecuente en
	espacios de funciones.
\end{remark}

Para demostrar el teorema de existencia y unicidad de la solución, únicamente
nos queda por ver que existe un \(m \in \N\) tal que \(T^m\) es contractiva.

\begin{lemma} \label{prop:operator_int_ineq}
	Sean \(\vec{f}, \vec{g} \in C([\tilde{\alpha}, \tilde{\omega}], \R^n)\) y
	\(t \in [\tilde{\alpha}, \tilde{\omega}]\). Se cumple
	\[\norm{T(\vec{f})(t) - T(\vec{g})(t)}_2
		= \norm{\int_{t_0}^t A(s)(\vec{f}(s) - \vec{g}(s)) \dif s}_2
		\leq \int_{t_0}^t \norm{A(s)(\vec{f}(s) - \vec{g}(s))}_2 \dif s.\]
\end{lemma}
\begin{proof}
    Para demostrar la igualdad basta desarrollar la definición y usar la
    linealidad de la integral, mientras que la desigualdad es consecuencia
    de la desigualdad triangular para integrales.
\end{proof}

\begin{definition}[Norma como operador]
	Dada una matriz \(M \in \mathcal{M}_{n \times n}\), definimos su \emph{norma
	como operador} como
	\[\norm{M}_{op} \eqdef \max_{\norm{\vec{x}}_2 \leq 1} \norm{M \vec{x}}_2
		= \sup_{\vec{x} \neq \vec{0}}
			\frac{\norm{M \vec{x}}_2}{\norm{\vec{x}}_2}.\]
\end{definition}

\begin{remark} \label{prop:norm_op_eq}
	Para toda matriz \(M \in \mathcal{M}_{n \times n}\) y todo
	\(\vec{x} \in \R^n\), se cumple
	\[\norm{M \vec{x}}_2 \leq \norm{M}_{op} \norm{\vec{x}}_2.\]
\end{remark}

\begin{definition}[Norma infinito]
	Si \(A : X \subset \R \to \mathcal{M}_{n \times n}\), definimos su \emph{norma
	infinito} como
	\[\norm{A}_\infty \eqdef \sup_{x \in X} \norm{A(x)}_{op}.\]
\end{definition}

Así, del lema~\ref{prop:operator_int_ineq} y la nota~\ref{prop:norm_op_eq} se
deduce que
\begin{align*}
	\norm{T(\vec{f})(t) - T(\vec{g})(t)}_2
	&\leq \int_{t_0}^t \norm{A(s)}_{op} \norm{\vec{f}(s) - \vec{g}(s)}_2 \dif s
	\\
	&\leq \int_{t_0}^t \norm{A}_\infty \norm{\vec{f} - \vec{g}}_\infty \dif s \\
	&= \norm{A}_\infty\norm{\vec{f} - \vec{g}}_\infty(t - t_0).
\end{align*}
Como \(t, t_0 \in [\tilde{\alpha}, \tilde{\omega}]\), se tiene
\(\norm{T(\vec{f})(t) - T(\vec{g})(t)}_2
	\leq \norm{A}_\infty\norm{\vec{f} - \vec{g}}_2
		(\tilde{\omega} - \tilde{\alpha})\) y, tomando supremos,
\[\norm{T(\vec{f}) - T(\vec{g})}_\infty
	\leq \norm{A}_\infty(\tilde{\omega}
	- \tilde{\alpha}) \cdot \norm{\vec{f} - \vec{g}}_\infty,\]

es decir, \(T\) es Lipschitz de constante
\(\norm{A}_\infty(\tilde{\omega}-\tilde{\alpha})\). Ya habríamos acabado si esta
constante fuera menor que 1; en caso contrario, aún nos queda un poco de
trabajo.

\begin{lemma} \label{lem:desinfty}
	Para todo \(m \in \N\) se da la desigualdad
	\[\norm{T^m(\vec{f})(t) - T^m(\vec{g})(t)}_2
		\leq \frac{\norm{A}^m_\infty}{m!} \abs{t - t_0}^m
			\norm{\vec{f} - \vec{g}}_\infty.\]
\end{lemma}

\begin{proof}
	El caso base \(m = 1\) es lo que acabamos de probar; suponemos el resultado
    cierto para \(m\) y para \(m + 1\) se tiene, razonando como antes:
	\begin{align*}
		\norm{T^{m + 1}(\vec{f})(t) - T^{m + 1}(\vec{g})(t)}_2
		 & = \norm{T(T^m(\vec{f}))(t) - T(T^m (\vec{g}))(t)}_2 \\
		 & \leq \int_{t_0}^t \norm{A(s)}_{op}
		\norm{T^m(\vec{f})(s) - T^m (\vec{g})(s)}_2 \dif s,
	\end{align*}
	por la hipótesis de inducción:
	\begin{align*}
		\int_{t_0}^t \norm{A(s)}_{op}
		\norm{T^m(\vec{f})(s) - T^m(\vec{g})(s)}_2 \dif s
		 & \leq \int_{t_0}^t \norm{A}_\infty
		\frac{\norm{A}^m_\infty}{m!} \abs{s - t_0}^m
		\norm{\vec{f} - \vec{g}}_\infty \dif s \\
		 & \leq \frac{\norm{A}^{m + 1}_\infty}{m!}
		 \norm{\vec{f} - \vec{g}}_\infty \int_{t_0}^t \abs{s - t_0}^m \dif s,
	\end{align*}
	ahora sin más que integrar:
	\begin{align*}
		\norm{T^{m + 1}(\vec{f})(t) - T^{m + 1}(\vec{g})(t)}_2
		&\leq \frac{\norm{A}^{m + 1}_\infty}{m!}
		 	\norm{\vec{f} - \vec{g}}_\infty \frac{\abs{t - t_0}^{m + 1}}{m + 1}
		\\
		&= \frac{\norm{A}^{m + 1}_\infty}{(m + 1)!} \abs{t - t_0}^{m + 1}
		\norm{\vec{f} - \vec{g}}_\infty.
	\end{align*}
\end{proof}

\begin{remark}
	La desigualdad
	\[\norm{A(s)(\vec{f}(s) - \vec{g}(s))}_2
		\leq \norm{A}_\infty \norm{\vec{f} - \vec{g}}_\infty\]
	no es más que la propiedad de Lipschitz para \(A\),
	no hace falta la linealidad.
\end{remark}

\begin{corollary} \label{cor:T_norm_infty_ineq}
	Se da la desigualdad
	\[\norm{T^m(\vec{f}) - T^m(\vec{g})}_\infty
		\leq \frac{\norm{A}^m_\infty}{m!} (\tilde{\omega} - \tilde{\alpha})^m
		\norm{\vec{f} - \vec{g}}_\infty.\]
\end{corollary}

\begin{proof}
	Tomamos supremos en \(t\) en el lema~\ref{lem:desinfty}.
\end{proof}

Después de todos estos preámbulos podemos finalmente demostrar el teorema de
Picard, que es posiblemente el resultado más importante del curso.

\begin{theorem}[Picard]
	Si \(A(t)\), \(\vec{b}(t)\) son continuas en
	\((\alpha, \omega) \subset \R\), \(t_0 \in \R\) y \(\vec{x}^0 \in \R^n\),
	entonces el problema de valor inicial
	\[\eqsys{
		\vec{x}' = A(t)\vec{x} + \vec{b}(t) \\
		\vec{x}(t_0) = \vec{x}^0}\]
	tiene solución única en \((\alpha, \omega)\).
\end{theorem}

\begin{proof}
	Por el corolario~\ref{cor:T_norm_infty_ineq}, existe un \(m \in \N\) tal que
    \(T^m\) es contractiva. Podemos entonces aplicar el
    corolario~\ref{cor:banach_fixed_point} para concluir que \(T\) tiene un
    único punto fijo. Ahora bien, puesto que una función \(\vec{x}\) es solución
    del PVI si y solo si \(T(\vec{x}) = \vec{x}\), obtenemos el resultado.
\end{proof}

\begin{remark}
	La misma demostración prueba existencia y unicidad de la solución en el caso
    no lineal bajo hipótesis de lipschitzianidad en el \textquote{operador
      integral} correspondiente.
\end{remark}

Otra de las consecuencias del teorema del punto fijo de Banach es que
\(T^m(\vec{f}_0)\), donde \(\vec{f}_0\) es un punto inicial cualquiera, converge
exponencialmente rápido al punto fijo de \(T\). Esto nos da un método numérico
para aproximar la solución del PVI escogiendo un punto inicial simple
(constante). También nos proporciona el desarrollo en serie (analítico) de la
solución del PVI, este método se conoce como método de las iteraciones de
Picard.

\begin{corollary}[Iteraciones de Picard]
	La solución al anterior problema de valor inicial es el límite de la
	sucesión
	\[\eqsys{
		\vec{x}_0 = T(\vec{f}_0), & \vec{f}_0 : (\alpha, \omega) \to \R^n \text{ arbitraria}\\
		\vec{x}_m = T(\vec{x}_{m - 1})}\]
  que además se alcanza exponencialmente rápido. Si la solución es analítica la
  anterior sucesión proporciona su desarrollo en serie.
\end{corollary}

\begin{example}
	Resolver el siguiente PVI mediante las iteraciones de Picard:
	\[\eqsys{x' = ax \quad \text{(ecuación escalar)} \\
			x(0) = x_0}\]
\end{example}

\begin{solution}
	Iniciamos el proceso con la solución constante \(x_0\), aplicando la
    definición recursiva obtenemos
	\[x_1 = T(x_0) = x_0 + \int_0^t a x_0 \dif s = x_0 + x_0 a t,\]
	e iterando tenemos
	\[x_n = T(x_{n - 1}) = x_0 \sum_{k = 0}^n \frac{(at)^k}{k!}.\]
	Cuando \(n\) tiende a infinito nos queda
	\(x = \lim_n x_n = x_0 e^{at}\).
\end{solution}

Este procedimiento también vale, con las modificaciones obvias, para el caso
matricial, a diferencia de la separación de variables que ya vimos.

\section{Estructura del espacio de soluciones}

\subsection{Caso homogéneo}

Consideramos el sistema homogéneo \(\vec{x}' = A(t) \vec{x}\) y definimos el
operador
\begin{align*}
	T : C^1((\alpha, \omega), \R^n) & \to C((\alpha, \omega), \R^n) \\
							\vec{x} & \mapsto \vec{x}' - A(t)\vec{x},
\end{align*}
claramente \(\vec{x}\) es solución de la ecuación si y solo si
\(\vec{x} \in \ker(T)\).
Puesto que \(T\) es lineal el conjunto de soluciones es un espacio vectorial,
más propiamente un subespacio vectorial de \(C^1((\alpha, \omega), \R^n)\).

\begin{theorem}
	El espacio de soluciones de un sistema de \(n\) ecuaciones lineales
    homogéneas de primer orden es un subespacio vectorial de
    \(C^1((\alpha, \omega), \R^n)\) de dimensión \(n\). Además, si
    \(\vec{\phi}_j\) es la solución del problema de valor inicial
	\[\eqsys{
		\vec{x}' = A(t)\vec{x} \\
		\vec{x}(t_0) = \vec{e}_j = (0, \dots, \underset{j}{1}, \dots, 0)}\]
    siendo \(t_0 \in (\alpha, \omega)\) arbitrario, tenemos que
    \(\set{\vec{\phi}_1, \dots, \vec{\phi}_n}\) es una base de dicho espacio de
    soluciones.
\end{theorem}

\begin{proof}
	Demostramos primero que los \(\vec{\phi}_j\) son linealmente independientes.
	Si \(\alpha_1, \dots, \alpha_n\) son tales que
	\(\sum_{j = 1}^n \alpha_j \vec{\phi}_j \equiv \vec{0}\),
	evaluando en \(t_0\) se obtiene
	\[\sum_{j = 1}^n \alpha_j \vec{e}_j = \vec{0} \implies \alpha_j = 0,\]
	para todo \(j = 1, \dots, n\) como queríamos, por ser
	\(\vec{e}_1, \dots, \vec{e}_n\) base.
	Demostramos ahora que es sistema de generadores. Sea \(\vec{y}\) solución
	de la ecuación lineal y sea
	\(\vec{y}(t_0) = (\alpha_1, \dots, \alpha_n)\),
	definimos \(\vec{z} = \sum_{j = 1}^n \alpha_j \vec{\phi}_j\) y observamos
	que tanto \(\vec{y}\) como \(\vec{z}\) son soluciones de
	\[\eqsys{
		\vec{x}' = A(t)\vec{x} \\
		\vec{x}(t_0) = (\alpha_1, \dots, \alpha_n)}\]
	de donde deducimos que \(\vec{y} = \vec{z}\) en virtud del
	Teorema de Picard.
\end{proof}

\begin{definition}[Matriz fundamental]
	Llamaremos matriz fundamental del sistema
	\(\vec{x}' = A(t)\vec{x}\) y la denotaremos
	\(\Phi(t)\) a cualquier matriz cuyas columnas formen base del espacio de
	soluciones del mismo.
\end{definition}

Con las definiciones anteriores tenemos que
\(\Phi(t) \eqdef (\vec{\phi}_1, \vec{\phi}_2, \dots, \vec{\phi}_n)\) es una matriz
fundamental. Por la propia definición tenemos que si \(\Phi\) es una matriz
fundamental de un sistema de ecuaciones lineales homogéneas entonces la solución
general del sistema es \(\Phi(t)\vec{c}\) con \(\vec{c} \in \R^n\):
\[\vec{x}(t) = \Phi(t) \vec{c}
	= (\vec{\phi}_1, \dots, \vec{\phi}_n) \mat{c_1 \\ \vdots \\ c_n} =
	c_1\vec{\phi}_1 + \cdots + c_n\vec{\phi}_n.\]

\begin{proposition}
	Sea \(\Phi(t)\) una matriz cuyas columnas son solución del sistema
	\(\vec{x}' = A(t)\vec{x}\). Las siguientes afirmaciones son equivalentes:
	\begin{multicols}{2}
	\begin{enumerate}[i)]
		\item \(\Phi(t)\) es matriz fundamental.

		\item \(\det(\Phi(t)) \neq 0 \ \forall t \in (\alpha, \omega)\).

		\item \(\exists t_0 \in (\alpha, \omega) \ \det(\Phi(t_0)) \neq 0\).
	\end{enumerate}
	\end{multicols}
\end{proposition}

Las columnas de \(\Phi(t)\) son soluciones de \(\vec{x}' = A(t)\vec{x}\) si y
solo si \(\Phi(t)\) es solución de la ecuación matricial \(X' = A(t)X\), donde
\begin{align*}
	X : (\alpha, \omega) & \to \mathcal{M}_{n \times n} \\
	t                    & \mapsto X(t).
\end{align*}
Asimismo, que \(\Phi(t)\) sea matriz fundamental equivale a que sea solución de
un problema de valor inicial de la forma
\[\eqsys{X' = A(t)X \\ X(t_0) = X^0}\]
donde ambas igualdades son matriciales y \(\det(X_0) \neq 0\). Notamos que la
matriz fundamental \(\Phi(t) = (\vec{\phi}_1, \dots, \vec{\phi}_n)\) que
definimos anteriormente es la única solución del problema de valor inicial
\[\eqsys{X' = A(t)X \\ X(0) = \mathit{Id}}\]

\subsection{Caso no homogéneo}

La misma demostración del caso escalar prueba que la solución general de
\(\vec{x}' = A(t)\vec{x} + \vec{b}(t)\) es \(\vec{x}_p(t) + \vec{x}_h(t)\),
donde \(\vec{x}_p(t)\) es una solución particular arbitraria del sistema y
\(\vec{x}_h(t)\) es la solución general del sistema homogéneo asociado
\(\vec{x}' = A(t)\vec{x}\). Por lo visto arriba,
\(\vec{x}_h(t) = \Phi(t)\vec{c}\) con \(\vec{c} \in \R^n\), y como veremos más
adelante existen diversos métodos para obtener \(\vec{x}_p(t)\).

\section{Método de variación de constantes}

Un método para obtener una solución particular \(\vec{x}_p(t)\) de un sistema
\(\vec{x}' = A(t)\vec{x} + \vec{b}(t)\) es la técnica de variación de
constantes, que es completamente análoga a la que vimos en el caso de una variable.

Sabemos que la solución general de la ecuación homogénea asociada es
\(\vec{x}_h(t) = \Phi(t)\vec{c}\), conjeturamos la existencia
de una solución de la forma \(\vec{x}_p(t) = \Phi(t)\vec{c}(t)\):
\[\vec{x}'_p(t)
	= \Phi'(t) \vec{c}(t) + \Phi(t) \vec{c}'(t)
	= A(t)\Phi(t) \vec{c}(t) + \Phi(t) \vec{c}'(t).\]
Además, puesto que es solución del sistema homogéneo,
\[\vec{x}'_p(t) = A(t)\vec{x}_p(t) + \vec{b}(t)
	= A(t) \Phi(t) \vec{c}(t) + \vec{b}(t),\]
igualando ambas expresiones
\[\vec{c}'(t) = \Phi^{-1}(t) \vec{b}(t).\]

Basta por tanto elegir
\[\vec{c}(t) = \int_{t_0}^t \Phi^{-1}(s) \vec{b}(s) \dif s,\]

con lo que queda demostrado el siguiente teorema:

\begin{theorem}
	Sea \(\Phi(t)\) una matriz fundamental del sistema
	\(\vec{x}' = A(t)\vec{x}\), entonces
	\[\vec{x}_p(t) = \Phi(t) \int_{t_0}^t \Phi^{-1}(s) \vec{b}(s) \dif s\]
	con \(t_0 \in (\alpha, \omega)\) es una solución particular de
	\(\vec{x}' = A(t)\vec{x} + \vec{b}(t)\) que satisface
	\(\vec{x}_p(t_0) = \vec{0} \in \R^n\).
\end{theorem}

\section{Ecuación escalar de orden superior}

\begin{definition}
	\label{def:ecordsup}
	Una ecuación diferencial lineal de orden superior es una ecuación de la
	forma
	\[x^{(n)} = a_n(t) x^{(n - 1)} + \cdots + a_1(t)x + a_0(t).\]
\end{definition}

Definiendo las variables \(x_i = x^{(i - 1)}\), o lo que es lo mismo,
\(x_i = x'_{i - 1}\), la ecuación~\ref{def:ecordsup} es equivalente a
\[\eqsys{
	x_2 &= x'_1 \\
	x_3 &= x'_2 \\
	&\vdots \\
	x_n &= x'_{n - 1} \\
	x'_n &= a_n(t) x_n + \cdots + a_1(t) x_1 + a_0(t)
	}\]
donde la última ecuación es de primer orden, podemos también expresar este
sistema matricialmente como \(\vec{x}' = A(t)\vec{x} + \vec{b}(t)\) con:
\[A(t) = \mat{
		0 & 1 & & \\
		& \ddots & \ddots & \\
		& & 0 & 1 \\
		a_1(t) & a_2(t) & \cdots & a_n(t)
	}
	\quad \text{y} \quad
	\vec{b}(t) = \mat{0 \\ \vdots \\ 0 \\ a_0(t)}.
\]

En el caso del sistema, el problema de valor inicial consiste en fijar
\(x_1(t_0), x_2(t_0), \dots, x_n(t_0)\), lo que equivale a fijar
\(x(t_0), x'(t_0), \dots, x^{(n-1)}(t_0)\) en la ecuación de orden superior.
Aplicando lo visto anteriormente, la solución general del sistema viene dada por
\(\vec{x}_p(t) + \vec{x}_h(t)\) donde, como de costumbre, \(\vec{x}_p(t)\) es
una solución particular y \(\vec{x}_h(t)\) es la solución general de la ecuación
homogénea asociada, que tiene estructura de espacio vectorial de dimensión \(n\).

Si \(\vec{\phi}_1, \dots, \vec{\phi}_n\) son soluciones linealmente 
independientes de~\ref{def:ecordsup}, la matriz fundamental asociada al 
sistema equivalente es
\[\Phi(t) = \mat{
		\phi_1 & \dots & \phi_n \\
		\phi'_1 & \dots & \phi'_n \\
		\vdots & \ddots & \vdots \\
		\phi^{(n - 1)}_1 & \dots & \phi^{(n - 1)}_n}.\]

\begin{definition}[Wronskiano]
	Llamaremos \emph{Wronskiano} de \(\phi_1, \dots, \phi_n\) al determinante
	\[W(\phi_1, \dots, \phi_n)(t) \eqdef \det\mat{
			\phi_1(t) & \dots & \phi_n(t) \\
			\phi'_1(t) & \dots & \phi'_n(t) \\
			\vdots & \ddots & \vdots \\
			\phi^{(n - 1)}_1(t) & \dots & \phi^{(n - 1)}_n(t) \\
		}, \quad t \in (\alpha, \omega).\]
\end{definition}

\section{Matriz fundamental}

Hemos dejado pendiente cómo obtener una matriz fundamental \(\Phi(t)\) asociada
al sistema homogéneo \(\vec{x}' = A(t)\vec{x}\), en este curso nos
restringiremos al caso de coeficientes constantes, es decir,
\(\vec{x}' = A\vec{x}\) donde \(A\) es una matriz constante, no depende de
\(t\), lo que en particular implica que el dominio de definición será todo
\(\R\).

En el caso escalar, \(x' = ax\), sabemos que la solución es \(x = ke^{at}\),
donde podemos interpretar \(e^{at}\) como una 
\textquote{matriz fundamental \(1 \times 1\)}. 
En el caso matricial veremos que una matriz fundamental es
\(\Phi(t) = e^{At}\), aunque primero tendremos que definir la exponencial de una
matriz y obtener métodos para computarla.

\begin{lemma}
	\label{lem:expphi}
	Sea \(\Phi(t)\) la matriz fundamental asociada a las soluciones de
	\[\eqsys{
		\vec{x}' = A\vec{x} \\
		\vec{x}(0) = \vec{e}_j}\]
	o, equivalentemente, la única solución del problema de valor inicial
	\[\eqsys{
			X' = AX \\
			X(0) = \mathit{Id}}\]

	Se dan las siguientes igualdades:
	\begin{multicols}{3}
		\begin{enumerate}[i)]
			\item \(\displaystyle \Phi(0) = \mathit{Id}\)

			\item \(\displaystyle \Phi(t + s) = \Phi(t) \Phi(s)\)

			\item \(\displaystyle \Phi(-t) = \Phi^{-1}(t)\)
		\end{enumerate}
	\end{multicols}
\end{lemma}

\begin{proof}
	\begin{enumerate}[i), wide, labelwidth=0pt, labelindent=0pt]
		\item La primera igualdad se sigue directamente de la definición.

		\item Fijamos \(s\) y consideramos el problema de valor inicial
			\[\eqsys{\vec{x}' = A\vec{x} \\ \vec{x}(0) = \Phi(s) }\]
		      Vamos a ver que tanto \(\Phi(t + s)\) como \(\Phi(t)\Phi(s)\) (como
		      funciones en \(t\)) son soluciones de ese problema. Consideramos
		      primero \(X(t) \eqdef \Phi(t + s)\), tenemos que \(X(0) = \Phi(s)\) y
		      \[X'(t) = \Phi'(t + s) = A \Phi(t + s) = A X(t),\]
		      similarmente para \(Y(t) \eqdef \Phi(t)\Phi(s)\), aplicando la primera
		      igualdad \(Y(0) = \Phi(0)\Phi(s) = \Phi(s)\) e
		      \[Y'(t) = \Phi'(t)\Phi(s) = A \Phi(t)\Phi(s) = A Y(t).\]

		\item Aplicando la primera y segunda igualdad en los respectivos
		      miembros:
		      \[\mathit{Id} = \Phi(t + (-t)) = \Phi(t)\Phi(-t).\]
	\end{enumerate}
\end{proof}

Para la matriz fundamental \(\Phi\) así definida, 
\(\vec{x}(t) = \Phi(t)\vec{x}^0\) es la solución del sistema
\[\eqsys{\vec{x}' = A\vec{x} \\ \vec{x}(0) = \vec{x}^0}\]

\section{Exponencial de una matriz}

Notamos que la matriz que acabamos de definir \(\Phi\) tiene muchas de las
propiedades de la función exponencial, de hecho más adelante demostraremos que
\(\Phi(t) = \sum_{k=0}^\infty (tA)^k/k!\), por ahora nos contentamos con la
siguiente definición:

\begin{definition}[Exponencial de una matriz]
	Dada una matriz \(B\) se define su \emph{exponencial} \(\exp(B)\), o con la
    notación habitual \(e^B\), como
	\[e^B \eqdef \sum_{k = 0}^\infty \frac{B^k}{k!}.\]
\end{definition}

Presentamos ahora algunas propiedades típicas de la función exponencial que
también cumple esta versión matricial, las cuales se demuestran a partir de la
definición de forma análoga a las propiedades de la exponencial real.

\begin{proposition}
	Se cumplen las siguientes igualdades.
	\begin{multicols}{2}
		\begin{enumerate}[i)]
			\item \(\displaystyle e^0 = \mathit{Id}\)

			\item \(\displaystyle e^{(t + s)A} = e^{tA} e^{sA}\)

			\item \(\displaystyle \parens{e^{tA}}^{-1} = e^{-tA}\)

			\item \(\displaystyle \frac{d}{\dif t} e^{tA} = A e^{tA}\)
		\end{enumerate}
	\end{multicols}
\end{proposition}

\begin{remark}
	No es cierto en general que \(e^{A + B} = e^A e^B\), aunque sí se cumple si
    las matrices \(A\) y \(B\) conmutan.
\end{remark}

\begin{theorem}
	La matriz \(\Phi(t)\) definida en~\ref{lem:expphi} es igual a \(e^{At}\),
	dicho de otro modo:
	\[\Phi(t) = \sum_{k = 0}^\infty \frac{t^k A^k}{k!} =
		\sum_{k = 0}^\infty \frac{(tA)^k}{k!}.\]
\end{theorem}

\begin{proof}
	Haremos uso de las iteraciones de Picard, para ello definimos el operador
	\begin{align*}
		T : C((\alpha, \omega), \mathcal{M}_{n \times n}) 
		& \to C((\alpha, \omega), \mathcal{M}_{n \times n}) \\
		\Psi & \mapsto \mathit{Id} + \int_0^t A \Psi(s) \dif s.
	\end{align*}

	Comenzamos la iteración con \(X_0(t) = \mathit{Id}\) y proseguimos:
	\begin{align*}
		X_1 & = T(X_0) = \mathit{Id} + \int_0^t A \mathit{Id} \dif s =
		\mathit{Id} + At                                                      \\
		X_2 & = T(X_1) = \mathit{Id} + \int_0^t A (\mathit{Id} + As) \dif s =
		\mathit{Id} + At + \frac{A^2 t^2}{2}                                  \\
		    & \vdots                                                          \\
		X_n & = T(X_{n - 1}) =
		\mathit{Id} + At + \frac{A^2 t^2}{2} + \cdots + \frac{A^n t^n}{n!}
		= \sum_{k = 0}^n \frac{A^k t^k}{k!},
	\end{align*}
	tomando el límite \(\lim_{n \to \infty} X_n\) obtenemos el resultado.
\end{proof}

\section{Métodos de cómputo}

Con los resultados vistos arriba lo único que necesitamos para ser capaces de
resolver una ecuación escalar de orden superior son métodos para computar 
\(e^{A t}\) para \(A \in \mathcal{M}_{n \times n}(\R)\) arbitraria. 
A continuación presentamos métodos para distintos tipos de matrices, empezando
por el más concreto para terminar con uno válido para cualquier matriz cuadrada
real, cada uno de ellos se basa en el anterior, por lo que es recomendable
leer todos.

\subsection{Matrices diagonales}

Comenzamos con el caso más simple, una matriz diagonal, una vez visto este el
caso diagonalizable se sigue casi directamente.

\begin{proposition}
	Sea \(A\) una matriz diagonal, podemos expresar \(e^{At}\) como:
	\[e^{At} = \exp\mat{\lambda_1t & & \\ & \ddots & \\ & & \lambda_nt}
		= \mat{e^{\lambda_1 t} & & \\ & \ddots & \\ & & e^{\lambda_n t}}.\]
\end{proposition}

Presentamos dos demostraciones distintas, la primera usa resultados anteriores,
la segunda es directa.

\begin{proof}
	Sea \(A\) una matriz diagonal, entonces:
	\[A = \mat{
			\lambda_1 & & \\
			& \ddots & \\
			& & \lambda_n}
		\quad \text{y} \quad
		\vec{x}' = A\vec{x} \iff
		\eqsys{
			x'_1 &= \lambda_1 x_1 \\
			&\vdots \\
			x'_n &= \lambda_n x_n \\
		}
	\]
	La solución general de este sistema viene dada por
	\(x_1(t) = k_1 e^{\lambda_1 t}, \dots, x_n(t) = k_n e^{\lambda_n t}\) o, 
	lo que es lo mismo,
	\[\vec{x} = \mat{e^{\lambda_1 t} & & \\ & \ddots & \\ & & e^{\lambda_n t}}
		\mat{k_1 \\ \vdots \\ k_n}.\]
	Puesto que es solución del problema de valor inicial
	\(\set{X' = AX,\ X(0) = \mathit{Id}}\) hemos comprobado a posteriori, por
	la unicidad de la solución, que la matriz de la izquierda es \(e^{At}\). 
\end{proof}

Para convencernos lo comprobamos también directamente.

\begin{proof}
	Tenemos que
	\[e^{At} = \exp\smat{\lambda_1t & & \\ & \ddots & \\ & & \lambda_nt}
		= \sum_{k = 0}^\infty
		\frac{1}{k!}\smat{\lambda_1 & & \\ & \ddots & \\ & & \lambda_n}^k t^k
		= \sum_{k = 0}^\infty
		\frac{1}{k!} \smat{\lambda_1 t & & \\ & \ddots & \\ & & \lambda_n t}^k,
	\]
	ahora, explotando la diagonalidad:
	\[\sum_{k = 0}^\infty \frac{1}{k!} 
			\smat{\lambda_1 t & & \\ & \ddots & \\ & & \lambda_n t}^k
		= \sum_{k = 0}^\infty \frac{1}{k!} 
			\smat{(\lambda_1 t)^k & & \\ & \ddots & \\ & & (\lambda_n t)^k}
		= \mat{\sum_{k = 0}^\infty \frac{(\lambda_1 t)^k}{k!} & & \\
			& \ddots &
			\\ & & \sum_{k = 0}^\infty \frac{(\lambda_n t)^k}{k!}}.\]
\end{proof}

\subsection{Matrices diagonalizables con autovalores reales}

Sea \(A\) una matriz diagonalizable con autovalores reales
\(\lambda_1, \dots, \lambda_n\). 
Por álgebra lineal sabemos que si \(\{\vec{v}_1, \vec{v}_2, \dots, \vec{v}_n\}\)
es una base de autovectores asociados, entonces
\[P^{-1} A P = D = \mat{\lambda_1 && \\ & \ddots & \\ && \lambda_n}
	\quad \text{siendo} \quad
	P = \mat{\vec{v}_1 & \vec{v}_2 & \dots & \vec{v}_n}.\]

Gracias a esta descomposición podremos demostrar el siguiente teorema.

\begin{proposition}
	Sea \(A \in \mathcal{M}_{n \times n}(\R)\) diagonalizable con autovalores 
	reales. La solución general del sistema \(\vec{x}' = A\vec{x}\) es
	\[\vec{x}(t) = \mat{k_1 e^{\lambda_1 t} \\ \vdots \\ k_n e^{\lambda_n t}},
	\quad \mat{k_1 \\ \vdots \\ k_n} \in \R^n.\]
\end{proposition}

\begin{proof}
	Puesto que \(A\) es diagonalizable la ecuación \(\vec{x}' = A\vec{x}\) 
	se puede escribir como
	\(\vec{x}' = P D P^{-1} \vec{x}\). Con el cambio de variable 
	\(\vec{y} = P^{-1}\vec{x}\), nos queda
	\[\vec{x}' = A\vec{x} \iff 
		\vec{x}' = PDP^{-1}\vec{x} \iff 
		P^{-1}\vec{x}' = DP^{-1}\vec{x} \iff \vec{y}' = D\vec{y},\]
	donde es fundamental que \(P\) (y por tanto \(P^{-1}\)) sea una matriz constante
	para poder afirmar que \(\vec{y}' = (P^{-1}\vec{x})' = P^{-1}\vec{x}'\). 
	Con este cambio de variable podemos expresar la ecuación como
	\[\vec{y}' = \mat{\lambda_1 && \\ & \ddots & \\ && \lambda_n} \vec{y} \iff
		\vec{y} = e^{Dt}\vec{k} 
		= \mat{k_1 e^{\lambda_1 t} \\ \vdots \\ k_n e^{\lambda_n t}}.\]
\end{proof}

Tras estos preámbulos podemos obtener
una expresión explícita del espacio de soluciones
\begin{align*}
	\vec{x} &= P\vec{y} = \mat{\vec{v}_1 & \dots & \vec{v}_n} 
		\mat{k_1 e^{\lambda_1 t} \\ \vdots \\ k_n e^{\lambda_n t}} =
	k_1 e^{\lambda_1 t} \vec{v}_1 + \cdots + k_n e^{\lambda_n t}\vec{v}_n \\
	  &= P \mat{e^{\lambda_1 t} & & \\ & \ddots & \\ & & e^{\lambda_n t}}
      \mat{k_1 \\ \vdots \\ k_n} = P e^{D t} P^{-1} \mat{c_1 \\ \vdots \\ c_n} =
      e^{A t} \mat{c_1 \\ \vdots \\ c_n}
\end{align*}

\begin{remark}
	El espacio de soluciones es el espacio vectorial generado por
	\(\set{e^{\lambda_1 t} \vec{v}_1, \dots, e^{\lambda_n t} \vec{v}_n}\).
\end{remark}

\subsection{Matrices diagonalizables con autovalores complejos}

Consideramos ahora el caso diagonalizable general, en el que \(A\) puede tener
autovalores complejos. En estas condiciones, ya sabemos resolver 
\(\vec{x}' = A\vec{x}\) en \(\Complex\), es decir, si permitimos como solución 
\(\vec{z}(t) = \vec{x}(t) + \iu\vec{y}(t)\) porque todo lo
que hemos visto funciona igual para números complejos, pero puesto que nuestra 
matriz original solo tenía coeficientes reales no es descabellado asumir que lo 
que se busca son soluciones reales.

La siguiente proposición nos muestra una curiosa
propiedad de los autovalores complejos que explotaremos para obtener una matriz
semejante a la original cuya exponencial sea fácilmente computable.

\begin{proposition}
	Si \(A\) tiene coeficientes reales y \(\lambda\) es un autovalor complejo 
	de \(A\), entonces su conjugado \(\conjugate{\lambda}\) también lo es.
\end{proposition}

\begin{proof}
	El polinomio característico de \(A\), \(p(\lambda) = \det(A - \lambda I)\)
	tiene coeficientes reales, es decir, \(p(\lambda) = \sum_{i=1}^n
	a_i\lambda^i\) con \(a_i \in \R\).

	Si \(\lambda_0 \in \Complex\) es raíz del polinomio, es decir, \(\sum_{i=1}^n
	a_i\lambda_0^i = 0\), entonces

	\[0 = \conjugate{0} = \conjugate{\parens{\sum_{i=1}^n a_i\lambda_0^i}} 
		= \sum_{i=1}^n \conjugate{a_i}(\conjugate{\lambda_0})^i 
		= \sum_{i=1}^n a_i(\conjugate{\lambda_0})^i 
		= p(\conjugate{\lambda_0}).\]
\end{proof}

Por la proposición anterior los autovalores no reales siempre vienen por pares,
por lo que nos restringimos de momento a subespacios de dimensión 2.

\begin{proposition}
	Si \(\lambda = a + \iu b\) es un autovalor complejo de \(A\) y 
	\(\vec{w} = \vec{u} + \iu\vec{v}\)
	un autovector asociado, entonces \(\conjugate{\lambda} = a - \iu b\) 
	es también autovalor y \(\conjugate{\vec{w}} = \vec{u} - \iu \vec{v}\) es un 
	autovector asociado.
\end{proposition}

\begin{proof}
	Como \(\lambda\) es un autovalor con autovector \(\vec{w}\), se cumple
	\(A\vec{w} = \lambda \vec{w}\), por lo que
	\[\conjugate{(A\vec{w})} = \conjugate{(\lambda \vec{w})} 
		= \conjugate{\lambda} \conjugate{\vec{w}}
		\quad \text{y} \quad
	\conjugate{(A\vec{w})} = \conjugate{A} \conjugate{\vec{w}} 
		= A \conjugate{\vec{w}},\]
	luego \(A \conjugate{\vec{w}} = \conjugate{\lambda} \conjugate{\vec{w}}\).
\end{proof}

Vamos a ver cómo aprovechar esto para transformar una solución con números 
complejos en otra equivalente que involucre solamente números reales. 

\begin{proposition}
	Sea \(A \in \mathcal{M}_{2 \times 2}(\R)\) diagonalizable con un autovalor 
	complejo \(\lambda = a + \iu b\) y un autovector asociado 
	\(\vec{w} = \vec{u} + \iu\vec{v}\) entonces la solución general del sistema
	\(\vec{x}' = A\vec{x}\) es
	\[\vec{x}(t) = \mat{\vec{u} & \vec{v}} 
		\mat{e^{at}\cos bt & e^{at}\sin bt \\ -e^{at} \sin bt & e^{at}
		\cos bt} \mat{c_1 \\ c_2}, \quad \mat{c_1 \\ c_2} \in \R^2.\]
\end{proposition}

\begin{proof}
	Puesto que los autovalores complejos vienen en pares, \(A\) tiene como
	autovalores \(\lambda = a + \iu b\) y 
	\(\conjugate{\lambda} = a - \iu b \in \Complex\), 
	y autovectores asociados 
	\(\vec{w} = \vec{u} + \iu\vec{v}\) y 
	\(\conjugate{\vec{w}} = \vec{u} - \iu\vec{v}\). Se tiene que
	\[A\vec{u} + \iu A\vec{v} 
		= A\vec{w} = \lambda \vec{w} 
		= (a + \iu b)(\vec{u} + \iu \vec{v}) 
		= (a\vec{u} - b\vec{v}) + \iu(a\vec{v} + b\vec{u}),\]
	de donde, igualando partes real e imaginaria,
	\[\eqsys{
		A\vec{u} = a\vec{u} - b\vec{v} \\
		A\vec{v} = b\vec{u} + a\vec{v}}\]
	Ya hemos visto que \(\vec{u}\) y \(\vec{v}\) son linealmente independientes,
	por lo que la matriz \(P = \mat{\vec{u} & \vec{v}}\) 
	es una matriz de paso. Entonces,
	\[A \mat{\vec{u} & \vec{v}} 
		= \mat{A\vec{u} & A\vec{v}} 
		= \mat{a\vec{u} - b\vec{v} & b\vec{u} + a\vec{v}} 
		= \mat{\vec{u} & \vec{v}} \mat{a & b \\ -b & a},\]
	llamando \(B\) a la matriz de la derecha:
	\[B \eqdef \mat{a & b \\ -b & a}\]
	sin más que multiplicar por \(P^{-1}\) a la izquierda del primer y último
	miembro tenemos que las matrices \(A\) y \(B\) son semejantes, 
	\(P^{-1}AP = B\). 
	Sabemos que las soluciones de este sistema vienen dadas por 
	\(\vec{x}(t) = e^{At} \vec{k}\), como \(A = PBP^{-1}\) podemos escribir 
	\[\vec{x}(t) = e^{At} \mat{k_1 \\ k_2} 
		= P e^{Bt} P^{-1} \mat{k_1 \\ k_2} 
		= P e^{Bt} \mat{c_1 \\ c_2}.\]
	Así para conocer las soluciones reales del sistema solo necesitamos calcular
	\begin{align*}
		e^{Bt} &= \exp\mat{at & bt \\ -bt & at} 
			= \exp\parens{a\mat{1 & 0 \\ 0 & 1}t + b\mat{0 & 1 \\ -1 & 0}t} \\
			&= \mat{e^{at}  & 0 \\ 0 & e^{at}} 
			\exp\left(b\mat{0 & 1 \\ -1 & 0}t\right) 
			= e^{at}\exp\left(b\mat{0 & 1 \\ -1 & 0}t\right).
	\end{align*}
	
	Hemos simplificado nuestro problema al de resolver el caso 
	\(\vec{y}' = M\vec{y}\), donde
	\[M \eqdef \mat{0 & 1 \\ -1 & 0},\]
	es decir, calcular \(e^{Mt}\).
	Para ello, diagonalizamos \(M\); su polinomio característico es 
	\(p(\lambda) = \lambda^2 + 1\), luego sus
	autovalores son \(\pm \iu\). Los espacios invariantes son, respectivamente,
	\[\ker(M - \iu I) = L\left[\mat{1 \\ \iu}\right] 
		\quad \text{y} \quad 
		\ker(M + \iu I) = L\left[\mat{\iu \\ 1}\right],\]
	con lo que una posible matriz de paso es 
	\[P \eqdef \mat{1 & \iu \\ \iu & 1} \quad \text{con} \quad 
		P^{-1} = \frac{1}{2} \mat{1 & -\iu \\ -\iu & 1}.\]
	Se tiene entonces:
	\begin{align*}
		\exp \mat{0 & t \\ -t & 0} &= P^{-1} \exp\mat{\iu & 0 \\ 0 & -\iu} P =
		\frac{1}{2} \mat{1 & \iu \\ \iu & 1}
		\mat{e^{\iu t} & 0 \\ 0 & e^{-\iu t}} \mat {1 & -\iu \\ -\iu & 1} \\
		&= \frac{1}{2} 
		\mat{e^{\iu t} + e^{-\iu t} & -\iu e^{\iu t} + \iu e^{-\iu t} \\
		\iu e^{\iu t} - \iu e^{-\iu t} & e^{\iu t} + e^{-\iu t}} 
		= \mat{\cos t & \sin t \\ -\sin t & \cos t}.
	\end{align*}

	Juntando todo tenemos que las soluciones reales de \(\vec{x}' = A\vec{x}\) 
	son
	\[\vec{x}(t) = P 
		\mat{e^{at}\cos bt & e^{at}\sin bt \\
			-e^{at} \sin bt & e^{at} \cos bt} P^{-1} 
		\mat{k_1 \\ k_2} 
		= P \mat{e^{at}\cos bt & e^{at}\sin bt \\
			-e^{at} \sin bt & e^{at} \cos bt} \mat {c_1 \\ c_2}.\]
\end{proof}

Damos una demostración alternativa, ligeramente más directa, pero menos 
elemental.

\begin{proof}
	Sabemos, por lo visto anteriormente, que 
	\(\vec{z}(t) = e^{\lambda t} \vec{w}\) y
	\(\conjugate{\vec{z}}(t) = e^{\conjugate{\lambda} t} \conjugate{\vec{w}}\)
	son soluciones de \(\vec{x}' = A\vec{x}\) 
	linealmente independientes. Sin más que desarrollar los productos, se
	llega a:
	\begin{align*}
		\vec{z}(t) &= e^{(a + \iu b)t} (\vec{u} + \iu\vec{v}) 
		= e^{at} ((\vec{u}\cos bt - \vec{v}\sin bt) 
		+ \iu(\vec{v}\cos bt +\vec{u}\sin bt)) \\
		\conjugate{\vec{z}}(t) &= e^{(a - \iu b)t} (\vec{u} - \iu\vec{v}) 
		= e^{at} ((\vec{u}\cos bt - \vec{v}\sin bt) 
		- \iu(\vec{v}\cos bt + \vec{u}\sin bt)).
	\end{align*}
	Ahora bien, como:
	\[\mat{\Re(\vec{z}(t)) \\ \Im(\vec{z}(t))} 
		= \frac{1}{2} \mat{\vec{z}(t) + \conjugate{\vec{z}}(t) \\
			(\vec{z}(t) - \conjugate{\vec{z}}(t))/\iu} 
		= \frac{1}{2}\mat{1 & 1 \\ -\iu & \iu} 
		\mat{\vec{z}(t) \\ \conjugate{\vec{z}}(t)} 
		\quad \text{y} \quad 
		\det\mat{1 & 1 \\ -\iu & \iu} \neq 0,\]
	se cumple que \(\Re(\vec{z}(t))\) e \(\Im(\vec{z}(t))\) siguen siendo 
	soluciones y linealmente independientes, que además generan el mismo 
	espacio de soluciones. Tenemos entonces las soluciones reales:
	\[\eqsys{
		\vec{x}(t) = \Re(\vec{z}) = e^{at}(\vec{u}\cos bt - \vec{v}\sin bt) \\
		\vec{y}(t) = \Im(\vec{z}) = e^{at}(\vec{v}\cos bt + \vec{u}\sin bt)}\]
\end{proof}

Para resolver el caso diagonalizable general, es decir, matrices de dimensión
arbitraria con autovalores reales y complejos, vamos a combinar todo lo que 
hemos visto. 

Sea \(A\) una matriz con autovalores reales \(\lambda_1, \dots, \lambda_r\)
y autovalores complejos \(a_1 \pm \iu b_1, \dots, a_s \pm \iu b_s\) con 
\(b_j > 0\), donde en ambos casos se admiten repeticiones. 
Definimos las matrices \(B_1, \dots, B_s\) y la matriz \(P\) como:
\[B_j \eqdef \mat{a_j & b_j \\ -b_j & a_j} 
	\quad \text{y} \quad
	P = \mat{\vec{v}_1 & \cdots & \vec{v}_r 
		& \Re(\vec{w}_1) & \Im(\vec{w}_1) & 
		\cdots & \Re(\vec{w}_s) & \Im(\vec{w}_s)},\]
siendo \(\vec{v}_j\) y \(\vec{w}_j\) autovectores asociados a \(\lambda_j\) 
y \(a_j + \iu b_j\), respectivamente.

\begin{theorem}
	El sistema \(\vec{x}' = A\vec{x}\) tiene solución general real:
	\[\vec{x}(t) = P
		\mat{e^{\lambda_1 t} & & & & & \\
			& \ddots & & & & \\
			& & e^{\lambda_r t} & & & \\
			& & & e^{B_1 t} & & \\
			& & & & \ddots & \\
			& & & & & e^{B_s t}}
		\mat{c_1 \\ \vdots \\ c_r \\ k_1 \\ k_2 \\ \vdots \\ k_{2s-1}\\ k_{2s}},
		\quad 
		\mat{c_1 \\ \vdots \\ c_r \\ k_1 \\ k_2 \\ \vdots \\ k_{2s-1}\\ k_{2s}}
		\in \R^n,\]
	donde
	\[e^{B_j t} = e^{a_j t} \mat{\cos b_j t & \sin b_j t \\
		-\sin b_j t & \cos b_j t}, 
		\quad 
		j = 1, \dots, s.\]
\end{theorem}

\begin{proof}
	Puesto que los autovectores complejos siempre se presentan en
	pares obtendremos una matriz semejante a la original diagonal por bloques
	\(D\); la matriz de cambio de paso que nos permite hacer esto es \(P\), 
	sin más que multiplicar:
	\[D \eqdef \mat{\lambda_1 & & & & & & & \\
		& \ddots & & & & & & \\
		& & \lambda_r & & & & & \\
		& & & a_1 & b_1 & & & & \\
		& & & -b_1 & a_1 & & & & \\
		& & & & & \ddots & & \\
		& & & & & & a_s & b_s \\
		& & & & & & -b_s & a_s} = P^{-1}AP.\]
	Para resolver el sistema basta ahora obtener la exponencial de esta matriz,
	pero esto equivale a computar la exponencial de cada elemento de la diagonal,
	por bloques, igual que en el caso diagonal (¿por qué?):
	\[e^{A t} = P e^{D t} P^{-1} =
		\mat{e^{\lambda_1 t} & & & & & \\
			& \ddots & & & & \\
			& & e^{\lambda_r t} & & & \\
			& & & e^{B_1 t} & & \\
			& & & & \ddots & \\
			& & & & & e^{B_s t}}.\]
\end{proof}

Vemos ahora un ejemplo concreto de cómo aplicar este teorema.

\begin{example}
	Resolver el sistema \(\vec{x}' = A\vec{x}\), siendo
	\[A = \mat{1 & 0 & 0 \\ 6 & 2 & -3 \\ 1 & 3 & 2}.\]
\end{example}

\begin{solution}
	En primer lugar hay que diagonalizar la matriz: sus autovalores son
	\(\lambda_1 = 1\), \(\lambda_2 = 2 + 3\iu\) y \(\lambda_3 = 2 - 3\iu\), 
	con espacios propios asociados
	\[\ker(A - \lambda_1 I) = L \left[ \mat{10 \\ 3 \\ -19} \right], \quad
		\ker(A - \lambda_2 I) = L \left[ \mat{0 \\ 1 \\ -\iu} \right], \quad
		\ker(A - \lambda_3 I) = L \left[\mat{0 \\ 1 \\ \iu} \right],\]
	con lo que podemos tomar
	\[v_1 = \mat{10 \\ 3 \\ -19}, 
		\quad 
		v_2 = \Re\mat{0 \\ 1 \\ -\iu} 
		= \mat{0 \\ 1 \\ 0}, 
		\quad 
		v_3 = \Im\mat{0 \\ 1 \\ -\iu} = \mat{0 \\ 0 \\ -1}.\]
	Así, obtenemos la matriz de paso \(P\) tal que
	\[P = \mat{10 & 0 & 0 \\ 3 & 1 & 0 \\ -19 & 0 & -1}
		\quad \text{y} \quad
		P^{-1}AP = \mat{1 & & \\ & 2 & 3 \\ & -3 & 2},\]
	que no es diagonal pero sí diagonal por bloques, lo que nos permite tomar 
	la exponencial, por bloques:
	\[A = P \mat{1 & & \\ & 2 & 3 \\ & -3 & 2} P^{-1}
		\quad \text{y} \quad
		e^{At} = P \mat{e^t & & \\ & e^{2t} \cos 3t & e^{2t} \sin 3t \\ &
		-e^{2t} \sin 3t & e^{2t} \cos 3t} P^{-1}.\]
	La solución general del sistema es entonces
	\[\vec{x}(t) = P \mat{e^t & & \\ & e^{2t} \cos 3t & e^{2t} \sin 3t \\ &
		-e^{2t} \sin 3t & e^{2t} \cos 3t} \mat{c_1 \\ c_2 \\ c_3}, \quad
		\mat{c_1 \\ c_2 \\ c_3} \in \R^3.\]
\end{solution}

\subsection{Matrices no diagonalizables}

Para terminar con el análisis de los sistemas de ecuaciones diferenciales
lineales con coeficientes constantes, únicamente nos falta estudiar qué ocurre
cuando la matriz que define el sistema no es diagonalizable.

\begin{theorem}[Forma canónica de Jordan compleja]
	Sea \(A \in \mathcal{M}_{n \times n}(\Complex)\) con \(s\) autovectores
	linealmente independientes. Entonces, existe una matriz no singular \(P\)
	tal que \(P^{-1} A P = B\), donde \(B\) es una matriz diagonal por bloques,
	es decir,
	\[B = \mat{B_1 & & & \\ & B_2 & & \\ & & \ddots & \\ & & & B_s},\]
	donde cada \emph{bloque de Jordan} \(B_j\), \(j = 1, \dots, s\), 
	es una matriz de la forma
	\[B_j = \mat{\lambda & 1 & & \\ 
		& \lambda & \ddots & \\ 
		& & \ddots & 1 \\ 
		& & & \lambda},\]
	siendo \(\lambda\) autovalor de \(A\).
\end{theorem}

Cada autovalor de \(A\) apararece en \(B\) tantas veces como su multiplicidad 
algebraica. El número de bloques asociados a un mismo autovalor se corresponde 
con su multiplicidad geométrica.

\begin{remark}
	El caso diagonalizable corresponde al caso en que todos los bloques son \(1
	\times 1\).
\end{remark}

Como antes puesto que nuestra matriz \(A\) es semejante a una diagonal por
bloques obtener su exponencial consistirá en obtener la exponencial de los
bloques, veamos pues cómo calcular la exponencial de un bloque de Jordan 
arbitrario.

\begin{proposition}
	Sea \(B_\lambda\) un bloque de Jordan asociado a un autovalor \(\lambda\)
	con autoespacio de dimensión \(m\).
	Podemos expresar \(e^{B_\lambda t}\) como:
	\[e^{B_\lambda t} = 
	\mat{e^{\lambda t} & te^{\lambda t} & \frac{t^2}{2!}e^{\lambda t} & \cdots & \frac{t^{n_j-1}}{(n_j-1)!}e^{\lambda t} \\
	& e^{\lambda t} & te^{\lambda t}              & \ddots & \vdots                    \\
	&   & e^{\lambda t}              & \ddots & \frac{t^2}{2!}e^{\lambda t}            \\
	&   &                & \ddots & te^{\lambda t}                         \\
	&   &                &        & e^{\lambda t}}.\]
\end{proposition}

\begin{proof}
	Descomponemos \(B_\lambda\) en dos matrices más manejables, 
	\(B_\lambda = D + N\), las matrices \(D\) y \(N\) son:
	\[B_\lambda = 
		\mat{\lambda & 1 & & \\ & \lambda & \ddots & \\ & & \ddots & 1 \\ & &
			& \lambda} =
		\mat{\lambda & & & \\ & \lambda & & \\ & & \ddots & \\ & & & \lambda}
		+ \mat{0 & 1 & & \\ & 0 & \ddots & \\ & & \ddots & 1 \\ & & & 0}.\]
	Ya sabemos calcular \(e^{Dt}\), y hallar \(e^{Nt}\) tampoco es complicado. Sus
	potencias sucesivas son
	\[
		N^0 = \mat{1 & 0 & 0 & \cdots & 0      \\
			& 1 & 0 & \ddots & \vdots \\
			&   & 1 & \ddots & 0      \\
			&   &   & \ddots & 0      \\
			&   &   &        & 1 }, \quad
		N^1 = \mat{0 & 1 & 0 & \cdots & 0      \\
			& 0 & 1 & \ddots & \vdots \\
			&   & 0 & \ddots & 0      \\
			&   &   & \ddots & 1      \\
			&   &   &        & 0 }, \ \ \dots \ \ ,
		N^{n_j-1} = \mat{0 & 0 & 0 & \cdots & 1      \\
			& 0 & 0 & \ddots & \vdots \\
			&   & 0 & \ddots & 0      \\
			&   &   & \ddots & 0      \\
			&   &   &        & 0 }
	\]
	en particular, \(N\) es nilpotente de orden \(n_j\), por lo que basta
	aplicar la definición para obtener:
	\[e^{Nt} = \sum_{k=0}^\infty \frac{t^k}{k!}N^k = \sum_{k=0}^{n_j-1}
		\frac{t^k}{k!}N^k =
		\mat{1 & t & \frac{t^2}{2!} & \cdots & \frac{t^{n_j-1}}{(n_j-1)!} \\
			& 1 & t              & \ddots & \vdots                    \\
			&   & 1              & \ddots & \frac{t^2}{2!}            \\
			&   &                & \ddots & t                         \\
			&   &                &        & 1 }.
	\]
	Finalmente, como \(D = \lambda I_{m \times m}\) y \(N\) conmutan, se tiene
	\begin{align*}
		e^{B_\lambda t} &= e^{Dt + Nt} = e^{Dt} e^{Nt} 
			= (e^{\lambda t} I_{m \times m}) e^{Nt} = e^{\lambda t}e^{Nt} \\
			&= \mat{e^{\lambda t} & te^{\lambda t} & \frac{t^2}{2!}e^{\lambda t} & \cdots & \frac{t^{n_j-1}}{(n_j-1)!}e^{\lambda t} \\
				& e^{\lambda t} & te^{\lambda t}              & \ddots & \vdots                    \\
				&   & e^{\lambda t}              & \ddots & \frac{t^2}{2!}e^{\lambda t}            \\
				&   &                & \ddots & te^{\lambda t}                         \\
				&   &                &        & e^{\lambda t} }.
	\end{align*}
\end{proof}

Esto es suficiente en el caso de que \(A\) sólo tenga autovalores reales. Si
hay alguno complejo, hay que trabajar un poco más.

\begin{theorem}[Forma canónica de Jordan real]
	Sea \(A \in \mathcal{M}_{n \times n}(\R)\). Existe una matriz no singular
	\(P\) tal que \(P^{-1}AP = B\), donde \(B\) es una matriz diagonal por
	bloques. Dependiendo de sus autovalores estos bloques pueden tomar dos
	formas:
	\begin{enumerate}[align=left]
		\item[si \(\lambda\) es un autovalor real de \(A\):] 
			\[B_\lambda = \mat{\lambda & 1 & & \\ & \lambda & \ddots & \\ & & \ddots & 1 \\ & & & \lambda}.\]

		\item[si \(\lambda = a + \iu b\), \(b > 0\),
			es un autovalor complejo de \(A\):]
			\[B_\lambda = 
				\mat{D & I_{2 \times 2} & & \\ & D & \ddots & \\ & & \ddots &
				I_{2 \times 2} \\ & & & D}
				= \mat{a & b & 1 & 0 \\ -b & a & 0 & 1 
					\\ && a & b & 1 & 0 \\ && -b & a & 0 & 1
					\\ &&&&& \ddots & \ddots 
					 \\ &&&&&& a & b & 1 & 0 \\ &&&&&& -b & a & 0 & 1}.\]
	\end{enumerate}
\end{theorem}

A la vista de este teorema, para poder resolver cualquier ecuación diferencial
escalar de orden superior sólo nos falta saber calcular la exponencial de los
bloques de Jordan reales asociados a autovalores complejos.

\begin{proposition}
	Sea \(B_\lambda\) un bloque de Jordan real asociado a un autovalor complejo 
	\(\lambda\). Se puede escribir:
	\[e^{B_\lambda t} = 
		\mat{e^{Dt} & te^{Dt} & \frac{t^2}{2!}e^{Dt} & \cdots & \frac{t^{n_j-1}}{(n_j-1)!}e^{Dt} \\
			& e^{Dt} & te^{Dt}                  & \ddots & \vdots                      \\
			&   & e^{Dt}                   & \ddots & \frac{t^2}{2!}e^{Dt}             \\
			&   &                     & \ddots & te^{Dt}                          \\
			&   &                     &        & e^{Dt}},\]
	donde
	\[e^{Dt} = e^{a t} \mat{\cos bt & \sin bt \\ -\sin bt & \cos bt}.\]
\end{proposition}

\begin{proof}
	Como antes, buscamos una descomposición manejable 
	\(B_\lambda = \mathcal{D} + N\), las matrices que cumplen esto son:
	\[B_\lambda = 
		\mat{D & I_2 & & \\ & D & \ddots & \\ & & \ddots & I_2 \\ & & & D} 
		= \mat{D & & & \\ & D & & \\ & & \ddots & \\ & & & D} +
		\mat{0 & I_2 & & \\ & 0 & \ddots & \\ & & \ddots & I_2 \\ & & & 0}.\]
	Observamos que estas dos matrices conmutan, esto es \(\mathcal{D}N =
	N\mathcal{D}\), luego la exponencial de su suma es
	\[e^{B_\lambda t} =
		e^{\mathcal{D}t} e^{Nt}
		= \mat{e^{Dt} & & & \\ & e^{Dt} & & \\ & & \ddots & \\ & & & e^{Dt}}
		e^{Nt}.\]
	Ya sabemos calcular la exponencial de \(e^{\mathcal{D}t}\), por lo visto en
	la sección anterior. Por otro lado, igual que antes es fácil ver que
	\[e^{Nt} = \sum_{k=0}^{n_j-1} \frac{t^k}{k!}N^k =
		\mat{I_2 & tI_2 & \frac{t^2}{2!}I_2 & \cdots & \frac{t^{n_j-1}}{(n_j-1)!}I_2 \\
			& I_2  & tI_2              & \ddots & \vdots                        \\
			&      & I_2               & \ddots & \frac{t^2}{2!}I_2             \\
			&      &                   & \ddots & tI_2                          \\
			&      &                   &        & I_2 }.\]
	Juntándolo todo obtenemos el resultado.
\end{proof}

Ahora que ya sabemos resolver cualquier sistema con coeficientes constantes,
centrémonos en cómo calcular la forma canónica de Jordan. La clave será
encontrar propiedades de \(B\) que caractericen su estructura de bloques y que
sean invariantes por semejanza, para poder hallarlas a partir de \(A\).

Por ser \(P\) no singular, se cumple \(\dim \ker (B - \lambda I) = \dim \ker
(P^{-1}(A - \lambda I)P) = \dim \ker (A - \lambda I)\) o, equivalentemente,
\(\ran (A - \lambda I) = \ran (B - \lambda I)\).

Recordando la estructura de \(B\), es fácil ver que
\(\dim \ker (B - \lambda I) = \sum_{i=1}^r \nu_i(\lambda)\), siendo
\(\nu_i(\lambda)\) el número de bloques de tamaño \(i \times i\) del autovalor
\(\lambda\).

Consideramos ahora potencias sucesivas de la matriz \(B - \lambda I\). Al
elevar al cuadrado, la dimensión del núcleo aumenta en una unidad por cada
bloque de tamaño mayor que 1:

\[
	B_j - \lambda I =
	\mat{0 & 1 &   &        &        &   \\
		& 0 & 1 &        &        &   \\
		&   & 0 & 1      &        &   \\
		&   &   & \ddots & \ddots &   \\
		&   &   &        & \ddots & 1 \\
		&   &   &        &        & 0 \\} \qquad
	(B_j - \lambda I)^2 =
	\mat{0 & 0 & 1      &        &        &   \\
		& 0 & 0      & 1      &        &   \\
		&   & \ddots & \ddots & \ddots &   \\
		&   &        & \ddots & \ddots & 1 \\
		&   &        &        & \ddots & 0 \\
		&   &        &        &        & 0 \\},
\]
por lo que
\(\dim \ker (B - \lambda I)^2 = \nu_1(\lambda) + 2 \sum_{i=2}^r
\nu_i(\lambda)\). Análogamente, para las terceras potencias se tiene
\(\dim \ker (B - \lambda I)^3 = \nu_1(\lambda) + 2\nu_2(\lambda) + 3
\sum_{i=3}^r \nu_i(\lambda)\) y, en general, para \(k = 1, \dots, r\):
\begin{align*}
	\dim \ker (B - \lambda I)^k & = \sum_{i=1}^{k-1} i \nu_i(\lambda) + k
	\sum_{i=k}^r \nu_i(\lambda)                                                         \\
	                            & = \nu_1(\lambda) + \cdots + (k-1)\nu_{k-1}(\lambda) +
	k[\nu_k(\lambda) + \cdots + \nu_r(\lambda)]
\end{align*}

\begin{remark}
	\(P(B - \lambda I)^kP^{-1} = (A - \lambda I)^k\) y, como el rango es
	invariante por semejanza, \(\dim \ker (A - \lambda I)^k = \dim \ker (B -
	\lambda I)^k\).
\end{remark}

\begin{remark}
	Los números \(\nu_i(\lambda)\) caracterizan \(B\), salvo permutación de bloques.
\end{remark}

Denotamos \(\delta_i(\lambda) = \dim \ker (A - \lambda I)^i\). De esta forma,
\(r\) es el menor número natural tal que \(\delta_r(\lambda) =
\delta_{r+1}(\lambda)\) y se verifica

\[\left\{
	\begin{array}[ht]{r c l}
		\delta_1(\lambda) & =      & \nu_1(\lambda) + \nu_2(\lambda) + \cdots +
		\nu_r(\lambda)                                                                           \\
		\delta_2(\lambda) & =      & \nu_1(\lambda) + 2[\nu_2(\lambda) + \cdots +
		\nu_r(\lambda)]                                                                          \\
		                  & \vdots &                                                             \\
		\delta_r(\lambda) & =      & \nu_1(\lambda) + 2\nu_2(\lambda) + \cdots + r\nu_r(\lambda)
	\end{array}
	\right.
\]

Restando a cada ecuación la anterior, queda un sistema triangular

\[\left\{
	\begin{array}[ht]{r c c c c c c c c}
		\delta_1(\lambda)                          & =      & \nu_1(\lambda) & + & \nu_2(\lambda) & + & \cdots & + & \nu_r(\lambda) \\
		-\delta_1(\lambda) + \delta_2(\lambda)     & =      &                &   & \nu_2(\lambda) & + & \cdots & + & \nu_r(\lambda) \\
		                                           & \vdots &                                                                       \\
		-\delta_{r-1}(\lambda) + \delta_r(\lambda) & =      &                &   &                &   &        &   & \nu_r(\lambda)
	\end{array}
	\right.
\]

que tiene por solución

\[\left\{
	\begin{array}[ht]{r c l}
		\nu_1(\lambda) & = & 2\delta_1(\lambda) - \delta_2(\lambda)                              \\
		\nu_k(\lambda) & = & -\delta_{k-1}(\lambda) + 2\delta_k(\lambda) - \delta_{k+1}(\lambda)
	\end{array}
	\right.
\]

Pasar de la forma de Jordan compleja a la real se hace como uno podría
esperar:

\[B_\Complex =
	\mat{\ddots &      &      &      &      &         \\
		& a + \iu b & 1    &      &      &         \\
		& 0    & a + \iu b &      &      &         \\
		&      &      & a - \iu b & 1    &         \\
		&      &      & 0    & a - \iu b &         \\
		&      &      &      &      & \ddots} \leadsto
	B_\R =
	\mat{\ddots &    &   &    &      &         \\
		& a  & b & 1  & 0 &         \\
		& -b & a & 0  & 1 &         \\
		&    &   & a  & b &         \\
		&    &   & -b & a &         \\
		&    &   &    &   & \ddots},
\]

pero esto requiere modificar también la matriz de paso compleja:

\[P_\Complex =
	\mat{\cdots & v_i & v_{i+1} & \cdots} \leadsto
	P_\R =
	\mat{\cdots & \Re(v_i) & \Im(v_i) & \cdots}\]

Falta únicamente ver cómo calcular
\(P_\Complex = \mat{v_1 & v_2 & \cdots & v_n}\). Para ello, es suficiente
estudiar cómo afecta \(B\) a los vectores de la base canónica, puesto que
\(A\) y la base \(\{v_i : i = 1, \dots, n\}\) se obtienen con el cambio de
base dado por \(P_\Complex\). Si el bloque \(j\)-ésimo de la matriz \(B\) (de
tamaño \(n_j \times n_j\)) empieza en el índice \(l+1\), se tiene

\[\left\{
	\begin{array}[ht]{r c l}
		Av_{l+1}    & =      & \lambda v_{l+1}                 \\
		Av_{l+2}    & =      & \lambda v_{l+2} + v_{l+1}       \\
		            & \vdots &                                 \\
		A v_{l+n_j} & =      & \lambda v_{l+n_j} + v_{l+n_j-1}
	\end{array} \right. \iff
	\left\{
	\begin{array}[ht]{r c l}
		Av_{l+1} & = & \lambda v_{l+1}                               \\
		Av_{l+k} & = & \lambda v_{l+k} + v_{l+k-1}, \ 1 < k \leq n_j \\
	\end{array}
	\right.\]

Estas ecuaciones (junto con el hecho de que \(P\) es invertible)
caracterizan \(P\).

\end{document}
